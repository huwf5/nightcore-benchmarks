#!/usr/bin/python3

import os
import sys
import time
import json
import yaml
import random
import string
import argparse
import subprocess as sp

ALIYUN_REGION = 'cn-hongkong'
ALIYUN_REGION_ID = 'cn-hongkong'
# TODO: export image to public
IMAGE_ID = 'm-j6c8afni7d7v37e89s39'
SECURITY_GROUP_NAME = 'nightcore'
DEPLOYMENT_SET_NAME = 'nightcore-experiments'
ZONE_ID = 'cn-hongkong-d'

# TODO: auto detect?
VSWITCH_ID = 'vsw-j6ccktc356urirhqyw8kn'

def random_string(length):
    letters = string.ascii_lowercase
    return ''.join(random.choice(letters) for _ in range(length))

def run_aliyun_ecs_command(cmd):
    ret = sp.run(['aliyun', 'ecs', '--region', ALIYUN_REGION, '--RegionId', ALIYUN_REGION_ID] + cmd,
                 stdout=sp.PIPE, stderr=sp.PIPE, encoding='utf8', cwd=os.environ['HOME'])
    if ret.returncode != 0:
        raise Exception('Failed to run aliyun ecs command: ' + ret.stderr)
    result = ret.stdout.strip()
    return json.loads(result) if result != '' else {}


def run_remote_command(ssh_str, cmd):
    ret = sp.run(['ssh', '-q', ssh_str, '--'] + cmd,
                 stdout=sp.PIPE, stderr=sp.PIPE, encoding='utf8')
    if ret.returncode != 0:
        raise Exception('Failed to run remote command: ' + ' '.join(cmd) + '\n' + ret.stderr)
    return ret.stdout, ret.stderr

def describe_ecs_instance(instance_id):
    cli_output = run_aliyun_ecs_command([
        'DescribeInstances', '--InstanceIds', '["' + instance_id + '"]', '--pager'
    ])
    return cli_output['Instances']['Instance'][0]

def add_to_hosts(dns, ip):
    command = f"echo '{ip} {dns}' | sudo tee -a /etc/hosts"
    ret = sp.run(command, shell=True, stdout=sp.PIPE, stderr=sp.PIPE, encoding='utf8')
    if ret.returncode != 0:
        raise Exception('Failed to add to hosts: ' + ret.stderr)

def remove_from_hosts(dns):
    command = f"sudo sed -i '/{dns}/d' /etc/hosts"
    ret = sp.run(command, shell=True, stdout=sp.PIPE, stderr=sp.PIPE, encoding='utf8')
    if ret.returncode != 0:
        raise Exception('Failed to remove from hosts: ' + ret.stderr)

def start_ecs_instance(name, instance_type, security_group_id, deployment_set_id):
    cli_output = run_aliyun_ecs_command([
        'RunInstances', '--ImageId', IMAGE_ID, '--InstanceType', instance_type,
        '--SecurityGroupId', security_group_id, '--InstanceName', name,
        '--InternetMaxBandwidthIn', '10', '--InternetMaxBandwidthOut', '100',
        '--DeploymentSetId', deployment_set_id, 
        '--VSwitchId', VSWITCH_ID, '--ZoneId', ZONE_ID,
        '--SystemDisk.Category', 'cloud_essd'
    ])
    instance_id = cli_output["InstanceIdSets"]["InstanceIdSet"][0]
    time.sleep(30)
    instance_info = describe_ecs_instance(instance_id)

    ip = instance_info['VpcAttributes']['PrivateIpAddress']['IpAddress'][0]

    # use fake dns to simplify the ssh configuration
    # add to /etc/hosts, which will be cleared when stop_instances is called
    dns = 'ecs-' + instance_id + '.compute.internal'
    add_to_hosts(dns, ip)

    return {
        'instance_id': instance_id,
        'dns': dns,
        'ip': ip
    }

def stop_instances(machine_infos):
    instance_ids = list(map(lambda x: x['instance_id'], machine_infos.values()))
    if len(instance_ids) == 0:
        return
    
    # clear fake dns
    for machine_info in machine_infos.values():
        remove_from_hosts(machine_info['dns'])

    # compose instance id params
    instance_id_params = []
    for index, instance_id in enumerate(instance_ids, start=1):
        instance_id_params.append(f'--InstanceId.{index}')
        instance_id_params.append(instance_id)
    
    run_aliyun_ecs_command(['DeleteInstances', '--Force', 'true'] + instance_id_params)

def find_security_group_id():
    cli_output = run_aliyun_ecs_command([
        'DescribeSecurityGroups', '--SecurityGroupName', SECURITY_GROUP_NAME,
        '--pager'
    ])
    if cli_output['SecurityGroups']['SecurityGroup'] is None or len(cli_output['SecurityGroups']['SecurityGroup']) == 0:
        raise Exception('Security group %s not found' % SECURITY_GROUP_NAME)    
    return cli_output['SecurityGroups']['SecurityGroup'][0]['SecurityGroupId']

def find_deployment_set_id():
    cli_output = run_aliyun_ecs_command([
        'DescribeDeploymentSets', '--DeploymentSetName', DEPLOYMENT_SET_NAME,
        '--pager'
    ])
    if cli_output['DeploymentSets']['DeploymentSet'] is None or len(cli_output['DeploymentSets']['DeploymentSet']) == 0:
        raise Exception('Deployment set %s not found' % DEPLOYMENT_SET_NAME)
    return cli_output['DeploymentSets']['DeploymentSet'][0]['DeploymentSetId']

def start_instances(machine_configs):
    security_group_id = find_security_group_id()
    deployment_set_id = find_deployment_set_id()
    results = {}
    for name, config in machine_configs.items():
        try:
            machine_info = start_ecs_instance(name, config['type'], security_group_id, deployment_set_id)
            machine_info['role'] = config['role']
            if 'labels' in config:
                machine_info['labels'] = config['labels']
            results[name] = machine_info
        except Exception as e:
            stop_instances(results)
            raise e
    return results

def setup_hostname_for_machines(machine_infos):
    for name, machine_info in machine_infos.items():
        run_remote_command(machine_info['dns'], ['sudo', 'hostnamectl', 'set-hostname', name])
    
def setup_docker_swarm_for_machines(machine_infos):
    manager_machine = None
    for name, machine_info in machine_infos.items():
        if machine_info['role'] == 'manager':
            if manager_machine is not None:
                raise Exception('More than one manager machine')
            run_remote_command(
                machine_info['dns'],
                ['docker', 'swarm', 'init', '--advertise-addr', machine_info['ip']])
            time.sleep(10)
            manager_machine = name
            join_token, _ = run_remote_command(
                machine_info['dns'],
                ['docker', 'swarm', 'join-token', '-q', 'worker'])
            join_token = join_token.strip()
    if manager_machine is None:
        raise Exception('No manager machine')
    for name, machine_info in machine_infos.items():
        if machine_info['role'] == 'worker':
            run_remote_command(
                machine_info['dns'],
                ['docker', 'swarm', 'join', '--token', join_token,
                 machine_infos[manager_machine]['ip']+':2377'])
    time.sleep(10)
    for name, machine_info in machine_infos.items():
        if 'labels' in machine_info:
            cmd = ['docker', 'node', 'update']
            for label_str in machine_info['labels']:
                cmd.extend(['--label-add', label_str])
            cmd.append(name)
            run_remote_command(machine_infos[manager_machine]['dns'], cmd)

def start_machines_main(base_dir):
    if os.path.exists(os.path.join(base_dir, 'machines.json')):
        raise Exception('Machines already started')
    with open(os.path.join(base_dir, 'config.json')) as fin:
        config = json.load(fin)
    machine_infos = start_instances(config['machines'])
    try:
        setup_hostname_for_machines(machine_infos)
        setup_docker_swarm_for_machines(machine_infos)
        with open(os.path.join(base_dir, 'machines.json'), 'w') as fout:
            json.dump(machine_infos, fout, indent=4, sort_keys=True)
    except Exception as e:
        stop_instances(machine_infos)
        raise e

def stop_machines_main(base_dir):
    if not os.path.exists(os.path.join(base_dir, 'machines.json')):
        raise Exception('Machines not started')
    with open(os.path.join(base_dir, 'machines.json')) as fin:
        machine_infos = json.load(fin)
    stop_instances(machine_infos)
    os.remove(os.path.join(base_dir, 'machines.json'))
    

def generate_docker_compose_main(base_dir):
    with open(os.path.join(base_dir, 'config.json')) as fin:
        config = json.load(fin)
    docker_compose = { 'version': '3.8', 'services': {} }
    for name, service_config in config['services'].items():
        docker_compose['services'][name] = { 'deploy': {} }
        service_docker_compose = docker_compose['services'][name]
        service_docker_compose['deploy']['replicas'] = service_config.get('replicas', 1)
        if 'placement' in service_config:
            service_docker_compose['deploy']['placement'] = {
                'constraints': ['node.hostname == %s' % (service_config['placement'],)]
            }
        elif 'placement_label' in service_config:
            service_docker_compose['deploy']['placement'] = {
                'constraints': ['node.labels.%s == true' % (service_config['placement_label'],)],
                'max_replicas_per_node': 1
            }
    with open(os.path.join(base_dir, 'docker-compose-placement.yml'), 'w') as fout:
        yaml.dump(docker_compose, fout, default_flow_style=False)

def get_host_main(base_dir, machine_name):
    if not os.path.exists(os.path.join(base_dir, 'machines.json')):
        raise Exception('Machines not started')
    with open(os.path.join(base_dir, 'machines.json')) as fin:
        machine_infos = json.load(fin)
    print(machine_infos[machine_name]['dns'])

def get_service_host_main(base_dir, service_name):
    if not os.path.exists(os.path.join(base_dir, 'machines.json')):
        raise Exception('Machines not started')
    with open(os.path.join(base_dir, 'config.json')) as fin:
        config = json.load(fin)
    with open(os.path.join(base_dir, 'machines.json')) as fin:
        machine_infos = json.load(fin)
    machine = config['services'][service_name]['placement']
    print(machine_infos[machine]['dns'])

def get_docker_manager_host_main(base_dir):
    if not os.path.exists(os.path.join(base_dir, 'machines.json')):
        raise Exception('Machines not started')
    with open(os.path.join(base_dir, 'machines.json')) as fin:
        machine_infos = json.load(fin)
    for machine_info in machine_infos.values():
        if machine_info['role'] == 'manager':
            print(machine_info['dns'])
            break

def get_client_host_main(base_dir):
    if not os.path.exists(os.path.join(base_dir, 'machines.json')):
        raise Exception('Machines not started')
    with open(os.path.join(base_dir, 'machines.json')) as fin:
        machine_infos = json.load(fin)
    for machine_info in machine_infos.values():
        if machine_info['role'] == 'client':
            print(machine_info['dns'])
            break

def get_all_server_hosts_main(base_dir):
    if not os.path.exists(os.path.join(base_dir, 'machines.json')):
        raise Exception('Machines not started')
    with open(os.path.join(base_dir, 'machines.json')) as fin:
        machine_infos = json.load(fin)
    for machine_info in machine_infos.values():
        if machine_info['role'] != 'client':
            print(machine_info['dns'])

def get_machine_with_label_main(base_dir, label):
    if not os.path.exists(os.path.join(base_dir, 'machines.json')):
        raise Exception('Machines not started')
    with open(os.path.join(base_dir, 'config.json')) as fin:
        config = json.load(fin)
    with open(os.path.join(base_dir, 'machines.json')) as fin:
        machine_infos = json.load(fin)
    for name, machine_info in machine_infos.items():
        if 'labels' in config['machines'][name]:
            labels = config['machines'][name]['labels']
            if label in labels or label+'=true' in labels:
                print(machine_info['dns'])

def get_container_id_main(base_dir, service_name, machine_name):
    if not os.path.exists(os.path.join(base_dir, 'machines.json')):
        raise Exception('Machines not started')
    with open(os.path.join(base_dir, 'machines.json')) as fin:
        machine_infos = json.load(fin)
    if machine_name is None:
        with open(os.path.join(base_dir, 'config.json')) as fin:
            config = json.load(fin)
        machine_name = config['services'][service_name]['placement']
    machine_info = machine_infos[machine_name]
    short_id, _ = run_remote_command(machine_info['dns'],
                                     ['docker', 'ps', '-q', '-f', 'name='+service_name])
    short_id = short_id.strip()
    if short_id != '':
        container_info, _ = run_remote_command(machine_info['dns'], ['docker', 'inspect', short_id])
        container_info = json.loads(container_info)[0]
        print(container_info['Id'])

def collect_container_logs_main(base_dir, log_path):
    if not os.path.exists(os.path.join(base_dir, 'machines.json')):
        raise Exception('Machines not started')
    os.makedirs(log_path, exist_ok=True)
    with open(os.path.join(base_dir, 'machines.json')) as fin:
        machine_infos = json.load(fin)
    for machine_info in machine_infos.values():
        if machine_info['role'] == 'client':
            continue
        container_ids, _ = run_remote_command(machine_info['dns'], ['docker', 'ps', '-q'])
        container_ids = container_ids.strip().split()
        for container_id in container_ids:
            container_info, _ = run_remote_command(
                machine_info['dns'], ['docker', 'inspect', container_id])
            container_info = json.loads(container_info)[0]
            container_name = container_info['Name'][1:]  # remove prefix '/'
            log_stdout, log_stderr = run_remote_command(
                machine_info['dns'], ['docker', 'container', 'logs', container_id])
            with open(os.path.join(log_path, '%s.stdout' % container_name), 'w') as fout:
                fout.write(log_stdout)
            with open(os.path.join(log_path, '%s.stderr' % container_name), 'w') as fout:
                fout.write(log_stderr)

if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument('cmd', type=str)
    parser.add_argument('--base-dir', type=str, default='.')
    parser.add_argument('--machine-name', type=str, default=None)
    parser.add_argument('--machine-label', type=str, default=None)
    parser.add_argument('--service', type=str, default=None)
    parser.add_argument('--use-spot-instances', action='store_true')
    parser.add_argument('--spot-instances-waiting-time', type=int, default=3)
    parser.add_argument('--log-path', type=str, default=None)
    args = parser.parse_args()
    try:
        if args.cmd == 'start-machines':
            start_machines_main(args.base_dir)
        elif args.cmd == 'stop-machines':
            stop_machines_main(args.base_dir)
        elif args.cmd == 'generate-docker-compose':
            generate_docker_compose_main(args.base_dir)
        elif args.cmd == 'get-host':
            get_host_main(args.base_dir, args.machine_name)
        elif args.cmd == 'get-service-host':
            get_service_host_main(args.base_dir, args.service)
        elif args.cmd == 'get-docker-manager-host':
            get_docker_manager_host_main(args.base_dir)
        elif args.cmd == 'get-client-host':
            get_client_host_main(args.base_dir)
        elif args.cmd == 'get-all-server-hosts':
            get_all_server_hosts_main(args.base_dir)
        elif args.cmd == 'get-machine-with-label':
            get_machine_with_label_main(args.base_dir, args.machine_label)
        elif args.cmd == 'get-container-id':
            get_container_id_main(args.base_dir, args.service, args.machine_name)
        elif args.cmd == 'collect-container-logs':
            collect_container_logs_main(args.base_dir, args.log_path)
        else:
            raise Exception('Unknown command: ' + args.cmd)
    except Exception as e:
        err_str = str(e)
        if not err_str.endswith('\n'):
            err_str += '\n'
        sys.stderr.write(err_str)
        sys.exit(1)
